Code Book

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Initial Dataset Information <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

The features selected for this database come from the accelerometer and gyroscope 3-axial raw signals tAcc-XYZ and tGyro-XYZ. These time domain signals (prefix 't' to denote time) were captured at 
a constant rate of 50 Hz. Then they were filtered using a median filter and a 3rd order low pass Butterworth filter with a corner frequency of 20 Hz to remove noise. Similarly, the acceleration 
signal was then separated into body and gravity acceleration signals (tBodyAcc-XYZ and tGravityAcc-XYZ) using another low pass Butterworth filter with a corner frequency of 0.3 Hz. 

Subsequently, the body linear acceleration and angular velocity were derived in time to obtain Jerk signals (tBodyAccJerk-XYZ and tBodyGyroJerk-XYZ). Also the magnitude of these three-dimensional 
signals were calculated using the Euclidean norm (tBodyAccMag, tGravityAccMag, tBodyAccJerkMag, tBodyGyroMag, tBodyGyroJerkMag). 

Finally a Fast Fourier Transform (FFT) was applied to some of these signals producing fBodyAcc-XYZ, fBodyAccJerk-XYZ, fBodyGyro-XYZ, fBodyAccJerkMag, fBodyGyroMag, fBodyGyroJerkMag. 
(Note the 'f' to indicate frequency domain signals). 

////////////////////////////////////////////////////////////////////////////////////////////////////////////////////// This information appears on table "SmartphonesData"
subject: individual number who perform the activity (30 in total)
activity: activity that perform the person (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING
, LAYING)

These signals were used to estimate variables of the feature vector for each pattern:  
'-XYZ' is used to denote 3-axial signals in the X, Y and Z directions.

tBodyAcc-XYZ
tGravityAcc-XYZ
tBodyAccJerk-XYZ
tBodyGyro-XYZ
tBodyGyroJerk-XYZ
tBodyAccMag
tGravityAccMag
tBodyAccJerkMag
tBodyGyroMag
tBodyGyroJerkMag
fBodyAcc-XYZ
fBodyAccJerk-XYZ
fBodyGyro-XYZ
fBodyAccMag
fBodyAccJerkMag

The set of variables that were estimated from these signals are: 

mean(): Mean value
std(): Standard deviation
angle(): Angle between to vectors. 

Additional vectors obtained by averaging the signals in a signal window sample. These are used on the angle() variable:

gravityMean
tBodyAccMean
tBodyAccJerkMean
tBodyGyroMean
tBodyGyroJerkMean

////////////////////////////////////////////////////////////////////////////////////////////////////////////////////// This information applies appears on table "SummarySmartphonesData"

subject: individual number who perform the activity (30 in total)
activity: activity that perform the person (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING
, LAYING)
rest of the variables: same variables as in the table "SmartphonesData" but in Average for each subject and activity combination

///////////////////////////////////////////////////////////////////////////////////////////////////////////////////// Processing Information for both tables

The next is the code in run_analysis.R file and the description of each step to transform the original datasets to the final two tables "SmartphonesData" and "SummarySmartphonesData"

############## Start of Code
run_analysis<-function () {
   #This function gather info from .txt files, merge the datasets into one in a tidy form, get 2 tidy data tables: one 
    #with selected variables that contains mean and standard deviation and the second one with calculated average 
    #for each varible for each subject and activity combination. Finally returns both tables to visualize them.
    
    
   library(dplyr) #to use mutate and select
    library(reshape2) #to use melt and dcast functions
   
    #The next functions are to load the .txt files into R. 
    #To work you need to set the Working Directory in the same folder where the de "data" folder is 
   activity_labels=read.table("./data/activity_labels.txt")
   features=read.table("./data/features.txt")
   X_test=read.table("./data/X_test.txt")
   y_test=read.table("./data/y_test.txt")
   subject_test=read.table("./data/subject_test.txt")
   X_train=read.table("./data/X_train.txt")
   y_train=read.table("./data/y_train.txt")
   subject_train=read.table("./data/subject_train.txt")
   
   #Create unique names for X dataset variables adding a number and an underscore as prefix. 
   #Otherwise you get an error when trying to convert the Data Frame to tbl_df for dplyr manipulation
   names_X<-c(paste0(features$V1,"_",as.character(features$V2))) 
   
   
   #Make "test" dataset tidy 
   names(X_test)<-names_X #Add names to columns (or variables)
   y_test$V1<-as.factor(y_test$V1) #Convert y_test to Factor to easily change numbers to categorical data
   levels(y_test$V1)<-activity_labels$V2 #Change numbers to labels on y_test to make it more descriptive
   X_test<-tbl_df(X_test) #Convert X_test to tbl_df for easy manipulation with dplyr functions
   X_test<-mutate(X_test,subject=subject_test$V1,activity=y_test$V1) #Add 2 columns: subject and activity
   
   #Perform same tidy process for "train" dataset
   names(X_train)<-names_X #Add names to columns (or variables)
   y_train$V1<-as.factor(y_train$V1) #Convert y_train to Factor to easily change numbers to categorical data
   levels(y_train$V1)<-activity_labels$V2 #Change numbers to labels on y_train to make it more descriptive
   X_train<-tbl_df(X_train) #Convert X_train to tbl_df for easy manipulation with dplyr functions
   X_train<-mutate(X_train,subject=subject_train$V1,activity=y_train$V1) #Add 2 columns: subject and activity
   
   
   #Convert and clean "train" and "test" dataset into one (SmarphonesData)
   SmartphonesData<-rbind(X_test,X_train) #Merge both datasets
   SmartphonesData<-select(SmartphonesData,subject,activity,contains("mean"),contains("std")) #Select just subject, activity and mean and std deviation for each measurement
   
   #Create second dataset with Summary 
   names(SmartphonesData)<-gsub("[0-9]+_","",names(SmartphonesData)) #Delete the number and underscore (previously added) from names
   names(SmartphonesData)<-gsub("\\(\\)","",names(SmartphonesData)) #Since parenthesis of this type "()" don't give any additional info, we delete them
   Data_Names<-names(SmartphonesData) #Extract dataset names for further processing
   Data_Names<-Data_Names[-(1:2)] #Select all names except "subject" and "activity" since these are the variables we want to group by
   
   SummarySmartphonesData<-melt(SmartphonesData,id=c("subject","activity"),measure.vars = Data_Names) #with this function we grab all the columns (or variables) data and put it in two columns: variable= name of the column and value= column value in that combination of subject & activity
   SummarySmartphonesData<-dcast(SummarySmartphonesData,subject + activity ~ variable,mean) #We obtain the mean of all the values of each variable with the same combination of subject & activity
   names(SummarySmartphonesData)[-(1:2)]<-gsub("^","Avg_",names(SummarySmartphonesData)[-(1:2)]) #We add the prefix "Avg_" to indicate that this columns
   #are average data in that activity and subject combination
   SummarySmartphonesData<-arrange(SummarySmartphonesData,subject,activity) #Order data by subject and activity
   SmartphonesData<-arrange(SmartphonesData,subject,activity) #Order data by subject and activity
   
   write.csv(SummarySmartphonesData,file="./SummarySmartphonesData.csv",row.names = FALSE)
   write.csv(SmartphonesData,file="./SmartphonesData.csv",row.names = FALSE)
   
   View(SmartphonesData) #Show table with variables that contains mean and standard deviation. See codebook for more info.
   View(SummarySmartphonesData) #Show table ith calculated average for each varible for each subject and activity combination

############## End of Code





